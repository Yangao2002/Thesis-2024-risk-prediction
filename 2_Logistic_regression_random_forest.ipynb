{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58a536-ba03-4425-9359-183e31cbfa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,accuracy_score,make_scorer, confusion_matrix, classification_report,accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, average_precision_score, fbeta_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score,cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from scipy.stats import chi2_contingency,kruskal,kendalltau\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from imblearn.pipeline import Pipeline as ImPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662d482-df02-4f54-bb13-e119eb1fc0cd",
   "metadata": {},
   "source": [
    "### **Split the data into train and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea8c81-388d-4e3f-80c1-46b19f3c90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_result = pd.read_csv('/Users/xxx/Desktop/LISS data/Cleaned_data.csv')\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "    imputed_result,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=imputed_result[['hypertension', 'age_group', 'male']]\n",
    ")\n",
    "\n",
    "test_male = test_data[test_data['male'] == 1]\n",
    "test_female = test_data[test_data['male'] == 0]\n",
    "test_age_1 = test_data[test_data['age_group'] == 1]\n",
    "test_age_2 = test_data[test_data['age_group'] == 2]\n",
    "test_age_3 = test_data[test_data['age_group'] == 3]\n",
    "test_age_4 = test_data[test_data['age_group'] == 4]\n",
    "test_age_5 = test_data[test_data['age_group'] == 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2039a6-373f-4318-ba27-8aec1e46bda1",
   "metadata": {},
   "source": [
    "### **Features sets for training various models** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d25d4-95fc-417d-be9f-c93b31a8ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 common risk factors\n",
    "\n",
    "base_variables = [\n",
    "    'male', \n",
    "    'age_group', \n",
    "    'BMI', \n",
    "    'chest_pain', \n",
    "    'angina', \n",
    "    'heart_dis', \n",
    "    'stroke', \n",
    "    'h_cholesterol', \n",
    "    'diabetes', \n",
    "    'smk'\n",
    "]\n",
    "\n",
    "# Model 2 common risk factors + psychological features\n",
    "\n",
    "variables_2 = base_variables + [\n",
    "    'anxiety',\n",
    "    'sleeping_prb', \n",
    "    'happiness',\n",
    "    'life_satisfaction_x'\n",
    "]   \n",
    "\n",
    "# Model 3 common risk factors + psychological features + common SES features\n",
    "\n",
    "variables_3 = base_variables + [\n",
    "    'anxiety',\n",
    "    'sleeping_prb', \n",
    "    'happiness',\n",
    "    'life_satisfaction_x',\n",
    "    'marr_Married',\n",
    "    'marr_Widow_widower',\n",
    "    'marr_Never_been_married',\n",
    "    'marr_Divorced_separated',\n",
    "    'occu_Is pensioner',\n",
    "    'occu_No employment',\n",
    "    'occu_Paid employment',\n",
    "    'edu_cls'\n",
    "]   \n",
    "\n",
    "# Model 4 common risk factors + psychological features + common SES features + incomes + debts\n",
    "\n",
    "variables_4 = base_variables + [\n",
    "    'anxiety',\n",
    "    'sleeping_prb', \n",
    "    'happiness',\n",
    "    'life_satisfaction_x',\n",
    "    'marr_Married',\n",
    "    'marr_Widow_widower',\n",
    "    'marr_Never_been_married',\n",
    "    'marr_Divorced_separated',\n",
    "    'occu_Is pensioner',\n",
    "    'occu_No employment',\n",
    "    'occu_Paid employment',\n",
    "    'edu_cls',\n",
    "    'inc_cls3_Low',\n",
    "    'inc_cls3_Medium',\n",
    "    'inc_cls3_High',\n",
    "    'inc_cls3_Very_High',\n",
    "    'db_ttl2_cls_None',\n",
    "    'db_ttl2_cls_Low',\n",
    "    'db_ttl2_cls_Medium',\n",
    "    'db_ttl2_cls_High',\n",
    "    'db_ttl2_cls_Very_High'\n",
    "]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d965bcb-1437-46f3-9781-ecd579299528",
   "metadata": {},
   "source": [
    "### **Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97e48ee-fa41-47a7-bed4-f69cdb4c79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train the model using the training set\n",
    "\n",
    "def evaluate_model(data, predictors, target, C, cv_splits=5):\n",
    "    X = data[predictors]\n",
    "    y = data[target]\n",
    "    \n",
    "    logreg = LogisticRegression(max_iter=100000,C=C)\n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "    \n",
    "    auc_scores = cross_val_score(logreg, X, y, cv=cv, scoring='roc_auc')\n",
    "    accuracy_scores = cross_val_score(logreg, X, y, cv=cv, scoring='accuracy')\n",
    "    f1_scores = cross_val_score(logreg, X, y, cv=cv, scoring='f1')\n",
    "    f2_scores = cross_val_score(logreg, X, y, cv=cv, scoring=f2_scorer)\n",
    "    recall_scores = cross_val_score(logreg, X, y, cv=cv, scoring='recall')\n",
    "    precision_scores = cross_val_score(logreg, X, y, cv=cv, scoring='precision')\n",
    "    \n",
    " # Prediction to compute confusion matrix and classification report    \n",
    "    y_pred = cross_val_predict(logreg, X, y, cv=cv)\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    report = classification_report(y, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Average AUC': np.mean(auc_scores),\n",
    "        'AUC SD': np.std(auc_scores),\n",
    "        'Average Accuracy': np.mean(accuracy_scores),\n",
    "        'Accuracy SD': np.std(accuracy_scores),\n",
    "        'Average F1 Score': np.mean(f1_scores),\n",
    "        'F1 Score SD': np.std(f1_scores),\n",
    "        'Average Recall': np.mean(recall_scores),\n",
    "        'Recall SD': np.std(recall_scores),\n",
    "        'Average Precision': np.mean(precision_scores),  # Include average precision score\n",
    "        'Precision SD': np.std(precision_scores),\n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Classification Report': report\n",
    "    }\n",
    "\n",
    "def print_evaluation_results(results):\n",
    "    print(\"Evaluation Results:\")\n",
    "    print(f\"Average AUC: {results['Average AUC']:.4f} (SD: {results['AUC SD']:.4f})\")\n",
    "    print(f\"Average Accuracy: {results['Average Accuracy']:.4f} (SD: {results['Accuracy SD']:.4f})\")\n",
    "    print(f\"Average F1 Score: {results['Average F1 Score']:.4f} (SD: {results['F1 Score SD']:.4f})\")\n",
    "    print(f\"Average Recall: {results['Average Recall']:.4f} (SD: {results['Recall SD']:.4f})\")\n",
    "    print(f\"Average Precision: {results['Average Precision']:.4f} (SD: {results['Precision SD']:.4f})\")  # Print the precision score results\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(results['Confusion Matrix'])\n",
    "    print(\"Classification Report:\")\n",
    "    print(results['Classification Report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee3b48-a622-4507-8fc4-287513efa173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "\n",
    "def evaluate_logistic_regression_on_test(lr, data, predictors, target):\n",
    "\n",
    "    X_test = data[predictors]\n",
    "    y_test = data[target]\n",
    "\n",
    "    # Perform predictions\n",
    "    y_pred = lr.predict(X_test)\n",
    "    y_probs = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    auc_score = roc_auc_score(y_test, y_probs)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Test Evaluation Results:\")\n",
    "    print(f\"AUC: {auc_score:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9dfbae-a950-422a-b68f-8576022c9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for logistic regression for the best C value\n",
    "\n",
    "def evaluate_model_f1_only(data, predictors, target, cv_splits=5):\n",
    "    X = data[predictors]\n",
    "    y = data[target]\n",
    "    \n",
    "    logreg = LogisticRegression(max_iter=100000, solver='liblinear')\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}  # Range of C values for L2 regularization\n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(logreg, param_grid, cv=cv, scoring='f1', refit=True)\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_f1 = grid_search.best_score_\n",
    "    \n",
    "    return {\n",
    "        'Best C': grid_search.best_params_['C'],\n",
    "        'Best F1': best_f1\n",
    "    }\n",
    "\n",
    "def print_best_f1(results):\n",
    "    print(\"Best Model Results:\")\n",
    "    print(f\"Best C: {results['Best C']}\")\n",
    "    print(f\"Best F1: {results['Best F1']:.4f}\")\n",
    "\n",
    "results = evaluate_model_f1_only(train_data, variables_4, 'hypertension')\n",
    "print_best_f1(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196d27ee-3005-4d0c-be7d-7a27f3590b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 1 \n",
    "\n",
    "results = evaluate_model(train_data,base_variables,'hypertension',C=100)\n",
    "print_evaluation_results(results)\n",
    "\n",
    "# test set\n",
    "lr = LogisticRegression(max_iter=1000, C=100)\n",
    "X_train = train_data[base_variables]\n",
    "y_train = train_data['hypertension']\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "evaluate_logistic_regression_on_test(lr, test_data, base_variables, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127a40a-eebc-4dc8-889f-51fc7fae8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set for male\n",
    "evaluate_logistic_regression_on_test(lr, test_male, base_variables, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a76913-05a4-43ca-9f9b-e59fcb6212cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set for female\n",
    "evaluate_logistic_regression_on_test(lr, test_female, base_variables, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ca36f-059e-4367-be5f-a0d4c348da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set for age gropus\n",
    "evaluate_logistic_regression_on_test(lr, test_age_1, base_variables, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f528500c-6512-4c63-9611-bdbfb159495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_logistic_regression_on_test(lr, test_age_2, base_variables, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2356e-fd84-4340-9256-c75e30015980",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_logistic_regression_on_test(lr, test_age_3, base_variables, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e1a9c-eec1-434d-b668-c0b420a9cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_logistic_regression_on_test(lr, test_age_4, base_variables, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd21fde9-2d4d-453b-b878-f15b315c7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_logistic_regression_on_test(lr, test_age_5, base_variables, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551af80-ef87-4f25-bb76-7c42ab6e832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Model 2\n",
    "\n",
    "results2 = evaluate_model(train_data,variables_2,'hypertension',C=10)\n",
    "print_evaluation_results(results2)\n",
    "\n",
    "# test set\n",
    "\n",
    "X_train = train_data[variables_2]\n",
    "y_train = train_data['hypertension']\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "evaluate_logistic_regression_on_test(lr, test_data, variables_2, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8654cff-e82f-47e2-9176-d39d26ab5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 3\n",
    "\n",
    "results3 = evaluate_model(train_data,variables_3,'hypertension',C=1)\n",
    "print_evaluation_results(results3)\n",
    "\n",
    "# test set\n",
    "\n",
    "X_train = train_data[variables_3]\n",
    "y_train = train_data['hypertension']\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "evaluate_logistic_regression_on_test(lr, test_data, variables_3, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d490754c-e897-4283-8bc5-50a93511b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 4 \n",
    "\n",
    "results4 = evaluate_model(train_data,variables_4,'hypertension',C=1)\n",
    "print_evaluation_results(results4)\n",
    "\n",
    "# test set\n",
    "\n",
    "X_train = train_data[variables_4]\n",
    "y_train = train_data['hypertension']\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "evaluate_logistic_regression_on_test(lr, test_data, variables_4, 'hypertension')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7a779-cc8f-4495-8557-abf9503ce67f",
   "metadata": {},
   "source": [
    "### **Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d39a4-bcb4-4f31-b888-601e9b718e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train the model using the training set\n",
    "\n",
    "def evaluate_random_forest(data, predictors, target, cv_splits=5, **rf_params):\n",
    "    \n",
    "    X = data[predictors]\n",
    "    y = data[target]\n",
    "\n",
    "    # Initialize the Random Forest classifier\n",
    "    rf = RandomForestClassifier(random_state=42, **rf_params)\n",
    "\n",
    "    # Set up cross-validation\n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform cross-validation and calculate metrics\n",
    "    auc_scores = cross_val_score(rf, X, y, cv=cv, scoring='roc_auc')\n",
    "    accuracy_scores = cross_val_score(rf, X, y, cv=cv, scoring='accuracy')\n",
    "    recall_scores = cross_val_score(rf, X, y, cv=cv, scoring='recall')\n",
    "    precision_scores = cross_val_score(rf, X, y, cv=cv, scoring='precision')\n",
    "    f1_scores = cross_val_score(rf, X, y, cv=cv, scoring='f1')\n",
    "    y_pred = cross_val_predict(rf, X, y, cv=cv)\n",
    "\n",
    "    # Calculate confusion matrix and classification report\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    report = classification_report(y, y_pred)\n",
    "\n",
    "    # Return a dictionary of the results\n",
    "    return {\n",
    "        'Average AUC': np.mean(auc_scores),\n",
    "        'AUC SD': np.std(auc_scores),  \n",
    "        'Average Accuracy': np.mean(accuracy_scores),\n",
    "        'Accuracy SD': np.std(accuracy_scores), \n",
    "        'Average F1 Score': np.mean(f1_scores),\n",
    "        'F1 Score SD': np.std(f1_scores),  \n",
    "        'Average Recall': np.mean(recall_scores),\n",
    "        'Recall SD': np.std(recall_scores), \n",
    "        'Average Precision': np.mean(precision_scores),\n",
    "        'Precision SD': np.std(precision_scores), \n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Classification Report': report\n",
    "    }\n",
    "\n",
    "def print_evaluation_results(results):\n",
    "    print(\"Evaluation Results:\")\n",
    "    print(f\"Average AUC: {results['Average AUC']:.4f} (SD: {results['AUC SD']:.4f})\")\n",
    "    print(f\"Average Accuracy: {results['Average Accuracy']:.4f} (SD: {results['Accuracy SD']:.4f})\")\n",
    "    print(f\"Average F1 Score: {results['Average F1 Score']:.4f} (SD: {results['F1 Score SD']:.4f})\")\n",
    "    print(f\"Average Recall: {results['Average Recall']:.4f} (SD: {results['Recall SD']:.4f})\")\n",
    "    print(f\"Average F2 Score: {results['Average F2 Score']:.4f} (SD: {results['F2 Score SD']:.4f})\")  # Print F2 score\n",
    "    print(f\"Average Precision: {results['Average Precision']:.4f} (SD: {results['Precision SD']:.4f})\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(results['Confusion Matrix'])\n",
    "    print(\"Classification Report:\")\n",
    "    print(results['Classification Report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903b9ea-2544-4831-87d6-2928dab10a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "\n",
    "def evaluate_random_forest_on_test(rf, data, predictors, target, threshold=0.5):\n",
    "    \n",
    "    X_test = data[predictors]\n",
    "    y_test = data[target]\n",
    "\n",
    "    # Perform predictions\n",
    "    y_probs = rf.predict_proba(X_test)[:, 1]  # probabilities for the positive class\n",
    "    y_pred = (y_probs >= threshold).astype(int)  # apply threshold to generate predictions\n",
    "\n",
    "    # Calculate metrics\n",
    "    auc_score = roc_auc_score(y_test, y_probs)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2) \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"Test Evaluation Results:\")\n",
    "    print(f\"AUC: {auc_score:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"F2 Score: {f2:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99550753-7a55-4e6f-85ef-56cfa543c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna for optimizing random forest parameters\n",
    "\n",
    "def objective(trial, data, predictors, target, cv_splits=5):\n",
    "    X = data[predictors]\n",
    "    y = data[target]\n",
    "\n",
    "    # Define hyperparameters to be tuned\n",
    "\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500, step=50)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 30)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    class_weight = trial.suggest_categorical('class_weight', ['balanced'])\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [False])\n",
    "    \n",
    "    # Initialize the Random Forest classifier with the suggested parameters\n",
    "    rf = RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        class_weight=class_weight,\n",
    "        bootstrap=bootstrap\n",
    "    )\n",
    "\n",
    "    # Set up cross-validation\n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # # Best F1\n",
    "    f1_scores = cross_val_score(rf, X, y, cv=cv, scoring='f1')\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# Run Optuna optimization\n",
    "def run_optuna(data, predictors, target, n_trials=50, cv_splits=5):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, data, predictors, target, cv_splits), n_trials=n_trials,show_progress_bar=False)\n",
    "    return study\n",
    "\n",
    "# Example usage:\n",
    "# study = run_optuna(train_data,base_variables,'hypertension',n_trials=500)\n",
    "# print(study.best_value)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee456f-cfd3-4d71-aed1-bc4ec0af01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the optimal threshold balancing precision and recall\n",
    "\n",
    "def plot_precision_recall_vs_threshold(model, data, predictors, target):\n",
    "\n",
    "    X_test = data[predictors]\n",
    "    y_test = data[target]\n",
    "\n",
    "    # Getting the probability scores of the positive class\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate precision, recall, and thresholds\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "    \n",
    "    # Calculate F1 score for each threshold\n",
    "    f1_scores = np.where((precision + recall) == 0, 0, 2*(precision*recall)/(precision+recall))\n",
    "\n",
    "    \n",
    "    # Identify the threshold that gives the best F1 score\n",
    "    best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "    best_f1_score = np.max(f1_scores)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, precision[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recall[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.plot(thresholds, f1_scores[:-1], \"r-\", label=\"F1 Score\")\n",
    "    plt.title(\"Precision, Recall, and F1 Score for different thresholds\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.axvline(x=best_threshold, color='gray', linestyle='--', label=f'Best Threshold: {best_threshold:.4f}')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Best F1 Score: {best_f1_score:.4f} at Threshold: {best_threshold:.4f}\")\n",
    "\n",
    "# plot_precision_recall_vs_threshold(rf, test_data, variables_4, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8212b-bf0c-43b9-b124-7f9fb4163478",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = run_optuna(train_data,base_variables,'hypertension',n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b9b4d-fc9a-4e16-a784-59bf68b271aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_value)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc16af9-d630-451c-b9dd-071917ec3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 with Optuna-tuned parameters, 'class_weight'='balanced' \n",
    "\n",
    "best_params = {'n_estimators': 100,\n",
    " 'max_depth': 10,\n",
    " 'min_samples_split': 16,\n",
    " 'min_samples_leaf': 10,\n",
    " 'max_features': 'sqrt',\n",
    " 'class_weight': 'balanced',\n",
    " 'bootstrap': True}\n",
    "\n",
    "\n",
    "results = evaluate_random_forest(train_data,base_variables,'hypertension',**best_params)\n",
    "print_evaluation_results(results)\n",
    "\n",
    "# # Test set\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "X_train = train_data[base_variables]\n",
    "y_train = train_data['hypertension']\n",
    "rf.fit(X_train, y_train) \n",
    "evaluate_random_forest_on_test(rf, test_data, base_variables, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec58bc-7681-4d6d-a573-0a3b7d792f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_vs_threshold(rf, test_data, base_variables, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d36e9-d4a8-41e6-b703-5b7924b69056",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_data, base_variables, 'hypertension',threshold=0.5807)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4cfab8-0c05-4f02-adee-a59d4fb37617",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = run_optuna(train_data,variables_2,'hypertension',n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db725873-44f0-4599-acde-0ecc74a411b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_value)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa559d22-6a6d-4bb2-bbbc-0ae53db26edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 with Optuna-tuned parameters, 'class_weight'='balanced' \n",
    "\n",
    "best_params = {'n_estimators': 100,\n",
    " 'max_depth': 18,\n",
    " 'min_samples_split': 19,\n",
    " 'min_samples_leaf': 7,\n",
    " 'max_features': 'log2',\n",
    " 'class_weight': 'balanced',\n",
    " 'bootstrap': False}\n",
    "\n",
    "results2 = evaluate_random_forest(train_data,variables_2,'hypertension',**best_params)\n",
    "print_evaluation_results(results2)\n",
    "\n",
    "# # Test set\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "X_train = train_data[variables_2]\n",
    "y_train = train_data['hypertension']\n",
    "rf.fit(X_train, y_train) \n",
    "evaluate_random_forest_on_test(rf, test_data, variables_2, 'hypertension',threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc67b9-d1b8-41d0-a9f3-2ff2921d9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_vs_threshold(rf, test_data, variables_2, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3655690b-a0ef-47ad-aa3e-320ededd62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_data, variables_2, 'hypertension',threshold = 0.5551)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef751966-41e5-465b-b723-d6495d59e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male\n",
    "evaluate_random_forest_on_test(rf, test_male, variables_2, 'hypertension',threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df797863-befc-4172-8309-c9c9b9d3dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female\n",
    "evaluate_random_forest_on_test(rf, test_female, variables_2, 'hypertension',threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a365ecca-f580-419d-9475-1290eca55b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age groups\n",
    "evaluate_random_forest_on_test(rf, test_age_1, variables_2, 'hypertension',threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3bb44d-4e6d-4e38-851e-25134088492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_age_2, variables_2, 'hypertension',threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde3b31-fa27-41f5-a447-fac1e3233733",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_age_3, variables_2, 'hypertension',threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25a4ee-2bcc-48ff-a3bf-a75aceb48ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_age_4, variables_2, 'hypertension',threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b85c223-1e56-44a4-8e06-57d904a7abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_age_5, variables_2, 'hypertension',threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f478ac-d157-47eb-a5eb-558ab0b55301",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = run_optuna(train_data,variables_3,'hypertension',n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc541f-332e-490d-8f1b-6d9533ed1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_value)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f8ad0-fb3d-4c8a-94b2-91af7aca2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 with Optuna-tuned parameters, 'class_weight'='balanced' \n",
    "\n",
    "best_params = {'n_estimators': 450,\n",
    " 'max_depth': 17,\n",
    " 'min_samples_split': 19,\n",
    " 'min_samples_leaf': 7,\n",
    " 'max_features': 'log2',\n",
    " 'class_weight': 'balanced',\n",
    " 'bootstrap': False}\n",
    "\n",
    "\n",
    "results3 = evaluate_random_forest(train_data,variables_3,'hypertension',**best_params)\n",
    "print_evaluation_results(results3)\n",
    "\n",
    "# # Test set\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "X_train = train_data[variables_3]\n",
    "y_train = train_data['hypertension']\n",
    "rf.fit(X_train, y_train) \n",
    "evaluate_random_forest_on_test(rf, test_data, variables_3, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fe576f-c68a-4434-9c62-d4f18a120ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_vs_threshold(rf, test_data, variables_3, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1c4a3-5ee8-4cc9-9308-2edad3788f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_data, variables_3, 'hypertension', threshold=0.5207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd22664-fa26-475b-b367-0c434284fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male\n",
    "evaluate_random_forest_on_test(rf, test_male, variables_3, 'hypertension',threshold = 0.5207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c613f0a-5f99-4fbf-8864-2f453bf13d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female\n",
    "evaluate_random_forest_on_test(rf, test_female, variables_3, 'hypertension',threshold = 0.5207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23efa5a9-3023-404f-adf6-d32ddcdffd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_age_1, variables_3, 'hypertension',threshold = 0.5207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0370724f-fa5a-49be-9818-3a67d1ed4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_age_2, variables_3, 'hypertension',threshold = 0.5207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252248f9-bc58-4f33-925d-a1614398665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_age_3, variables_3, 'hypertension',threshold = 0.5207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a5340-e90d-48e3-9644-9c1f0b6c29c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_age_4, variables_3, 'hypertension',threshold = 0.5207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94975af1-8294-4400-a6fd-dd0df3b07aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_age_5, variables_3, 'hypertension',threshold = 0.5207)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9182e-4825-44bf-91df-3dd2e5846f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = run_optuna(train_data,variables_4,'hypertension',n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87b965-8cd8-4544-a46a-16feecc800b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_value)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3c5eff-b1fc-4ad6-843d-2938106d688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 with Optuna-tuned parameters, 'class_weight'='balanced' \n",
    "\n",
    "best_params = {'n_estimators': 50,\n",
    " 'max_depth': 14,\n",
    " 'min_samples_split': 15,\n",
    " 'min_samples_leaf': 9,\n",
    " 'max_features': 'log2',\n",
    " 'class_weight': 'balanced',\n",
    " 'bootstrap': False}\n",
    "\n",
    "results4 = evaluate_random_forest(train_data,variables_4,'hypertension',**best_params)\n",
    "print_evaluation_results(results4)\n",
    "\n",
    "# # Test set\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "X_train = train_data[variables_4]\n",
    "y_train = train_data['hypertension']\n",
    "rf.fit(X_train, y_train) \n",
    "evaluate_random_forest_on_test(rf, test_data, variables_4, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed43d1-648b-49b8-8510-4995c3444f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_vs_threshold(rf, test_data, variables_4, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddafb9b-b549-4332-8a1c-3373dc883d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_random_forest_on_test(rf, test_data, variables_4, 'hypertension', threshold=0.4364)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d93eb2-71a4-40d1-a424-e26869aba4b3",
   "metadata": {},
   "source": [
    "### **Random forest with SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99f3f9-d29f-42d1-a0d2-b2f4901be838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train the model using the training set\n",
    "\n",
    "def evaluate_random_forest(data, predictors, target, cv_splits=5, k_neighbors=5, **best_params):\n",
    "    X = data[predictors]\n",
    "    y = data[target]\n",
    "\n",
    "    # Initialize SMOTE and Random Forest classifier\n",
    "    smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "    rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "\n",
    "    # Create a pipeline including SMOTE and Random Forest\n",
    "    pipeline = Pipeline([\n",
    "        ('smote', smote),\n",
    "        ('random_forest', rf)\n",
    "    ])\n",
    "\n",
    "    # Set up stratified cross-validation\n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform cross-validation and calculate metrics\n",
    "    auc_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc')\n",
    "    accuracy_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "    recall_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='recall')\n",
    "    precision_scores = cross_val_score(rf, X, y, cv=cv, scoring='precision')\n",
    "    f1_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='f1')\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=cv)\n",
    "\n",
    "    # Calculate confusion matrix and classification report\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    report = classification_report(y, y_pred)\n",
    "\n",
    "    # Return a dictionary of the results\n",
    "    return {\n",
    "        'Average AUC': np.mean(auc_scores),\n",
    "        'AUC SD': np.std(auc_scores),\n",
    "        'Average Accuracy': np.mean(accuracy_scores),\n",
    "        'Accuracy SD': np.std(accuracy_scores),\n",
    "        'Average F1 Score': np.mean(f1_scores),\n",
    "        'F1 Score SD': np.std(f1_scores),\n",
    "        'Average Recall': np.mean(recall_scores),\n",
    "        'Recall SD': np.std(recall_scores),\n",
    "        'Average Precision': np.mean(precision_scores),\n",
    "        'Precision SD': np.std(precision_scores), \n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Classification Report': report\n",
    "    }\n",
    "\n",
    "def print_evaluation_results(results):\n",
    "    print(\"Evaluation Results:\")\n",
    "    print(f\"Average AUC: {results['Average AUC']:.4f} (SD: {results['AUC SD']:.4f})\")\n",
    "    print(f\"Average Accuracy: {results['Average Accuracy']:.4f} (SD: {results['Accuracy SD']:.4f})\")\n",
    "    print(f\"Average F1 Score: {results['Average F1 Score']:.4f} (SD: {results['F1 Score SD']:.4f})\")\n",
    "    print(f\"Average Recall: {results['Average Recall']:.4f} (SD: {results['Recall SD']:.4f})\")\n",
    "    print(f\"Average Precision: {results['Average Precision']:.4f} (SD: {results['Precision SD']:.4f})\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(results['Confusion Matrix'])\n",
    "    print(\"Classification Report:\")\n",
    "    print(results['Classification Report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb07a86-b164-4c2f-b517-b9162c44f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate random forest model on test set\n",
    "\n",
    "def evaluate_random_forest_on_test(rf, data, predictors, target, threshold=0.5):\n",
    "\n",
    "    X_test = data[predictors]\n",
    "    y_test = data[target]\n",
    "\n",
    "    # Perform predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_probs = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    auc_score = roc_auc_score(y_test, y_probs)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Test Evaluation Results:\")\n",
    "    print(f\"AUC: {auc_score:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"F2 Score: {f2:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd2b15-ea32-4c47-8d55-e7d25f40feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna for optimizing random forest parameters\n",
    "\n",
    "def objective(trial, data, predictors, target, cv_splits=5):\n",
    "    X = data[predictors]\n",
    "    y = data[target]\n",
    "    # Define and suggest hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 500, step=50)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 30)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    class_weight = trial.suggest_categorical('class_weight', [None])\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [False])\n",
    "    smote_neighbors = trial.suggest_int('smote_neighbors', 3, 9)\n",
    "    # Setup the pipeline\n",
    "    pipeline = ImPipeline([\n",
    "        ('smote', SMOTE(k_neighbors=smote_neighbors)),\n",
    "        ('classifier', RandomForestClassifier(\n",
    "            random_state=42,\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            max_features=max_features,\n",
    "            class_weight=class_weight,\n",
    "            bootstrap=bootstrap\n",
    "        ))\n",
    "    ])\n",
    "    # Cross-validation\n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)\n",
    "    f1_scorer = make_scorer(f1_score)\n",
    "    f1_scores = cross_val_score(pipeline, X, y, cv=cv, scoring=f1_scorer, error_score='raise')\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "# Running the study\n",
    "def run_optuna(data, predictors, target, n_trials=50, cv_splits=5):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, data, predictors, target, cv_splits), n_trials=n_trials)\n",
    "    return study\n",
    "\n",
    "# study = run_optuna(train_data, base_variables, 'hypertension', n_trials=500)\n",
    "# best_params = study.best_trial.params\n",
    "# best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925c7d4-8332-477a-95fb-265822e2de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = run_optuna(train_data, base_variables, 'hypertension', n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d5cb1-3fb5-4c1f-9f4a-6e2864986472",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce41a8c-c5c6-405b-8a45-46493ecec687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 with Optuna-tuned parameters, 'class_weight'='none' \n",
    "\n",
    "best_params = {'n_estimators': 150,\n",
    " 'max_depth': 3,\n",
    " 'min_samples_split': 3,\n",
    " 'min_samples_leaf': 9,\n",
    " 'max_features': 'log2',\n",
    " 'class_weight': None,\n",
    " 'bootstrap': False\n",
    "              }\n",
    "\n",
    "results = evaluate_random_forest(train_data,base_variables,'hypertension',cv_splits=8, k_neighbors=6,**best_params)\n",
    "print_evaluation_results(results)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "X_train = train_data[base_variables]\n",
    "y_train = train_data['hypertension']\n",
    "rf.fit(X_train, y_train) \n",
    "evaluate_random_forest_on_test(rf, test_data, base_variables, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40dc00-3419-454a-b97e-e6409d228659",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = run_optuna(train_data, variables_2, 'hypertension', n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90527674-430f-43d8-ab9f-202358831340",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params2 = study.best_trial.params\n",
    "best_params2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea868a4a-dc84-42a0-9a54-38cc0b37a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 with Optuna-tuned parameters, 'class_weight'='none' \n",
    "\n",
    "best_params = {'n_estimators': 200,\n",
    " 'max_depth': 10,\n",
    " 'min_samples_split': 14,\n",
    " 'min_samples_leaf': 9,\n",
    " 'max_features': 'log2',\n",
    " 'class_weight': None,\n",
    " 'bootstrap': False\n",
    "              }\n",
    "\n",
    "results = evaluate_random_forest(train_data,variables_2,'hypertension',cv_splits=5, k_neighbors=3,**best_params)\n",
    "print_evaluation_results(results)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "X_train = train_data[variables_2]\n",
    "y_train = train_data['hypertension']\n",
    "rf.fit(X_train, y_train) \n",
    "evaluate_random_forest_on_test(rf, test_data, variables_2, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532bfb2c-db46-4ad5-8c17-3c46895b9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = run_optuna(train_data, variables_3, 'hypertension', n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc0337-a2c8-45b9-a9bc-8460095c8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params3 = study.best_trial.params\n",
    "best_params3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b97acb-6305-45bb-9178-12d201ceba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3 with Optuna-tuned parameters, 'class_weight'='none' \n",
    "\n",
    "best_params = {'n_estimators': 100,\n",
    " 'max_depth': 4,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 10,\n",
    " 'max_features': 'sqrt',\n",
    " 'class_weight': None,\n",
    " 'bootstrap': False\n",
    "              }\n",
    "\n",
    "results = evaluate_random_forest(train_data,variables_3,'hypertension',cv_splits=5, k_neighbors=6,**best_params)\n",
    "print_evaluation_results(results)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "X_train = train_data[variables_3]\n",
    "y_train = train_data['hypertension']\n",
    "rf.fit(X_train, y_train) \n",
    "evaluate_random_forest_on_test(rf, test_data, variables_3, 'hypertension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fa4d01-8463-4fe4-8b1b-be5ecbdaf3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = run_optuna(train_data, variables_4, 'hypertension', n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b6901-30ef-40a3-adde-286a761407c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params4 = study.best_trial.params\n",
    "best_params4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c87bf6-3e79-4a80-b113-a8441ef523f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4 with Optuna-tuned parameters, 'class_weight'='none' \n",
    "\n",
    "best_params = {'n_estimators': 50,\n",
    " 'max_depth': 4,\n",
    " 'min_samples_split': 16,\n",
    " 'min_samples_leaf': 8,\n",
    " 'max_features': 'sqrt',\n",
    " 'class_weight': None,\n",
    " 'bootstrap': False\n",
    "              }\n",
    "\n",
    "results = evaluate_random_forest(train_data,variables_4,'hypertension',cv_splits=3, k_neighbors=3,**best_params)\n",
    "print_evaluation_results(results)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, **best_params)\n",
    "X_train = train_data[variables_4]\n",
    "y_train = train_data['hypertension']\n",
    "rf.fit(X_train, y_train) \n",
    "evaluate_random_forest_on_test(rf, test_data, variables_4, 'hypertension')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
